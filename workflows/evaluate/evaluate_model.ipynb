{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e15d1-b995-48d7-88ed-69dac7cba069",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('../../USZ/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05614271-3c23-4588-8ea5-c179c99bab90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from tqdm import tqdm\n",
    "import plotnine as p9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "from joblib import Parallel, delayed\n",
    "#from plotnine_prism import *\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.utils import load_data\n",
    "from src.utils import bootstrapping\n",
    "from src.utils import compute_pearson_top_n\n",
    "from src.utils import compute_area_under_pearson_top_n\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82668d65-c5b2-4fdc-9f72-6c50f3bb007e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "out_folder = \"out_benchmark\"\n",
    "model = \"LinearRegression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a61b6-2419-4ee2-8693-1c5d436e2606",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"config_dataset.yaml\", \"r\") as stream:\n",
    "    config_dataset = yaml.safe_load(stream)\n",
    "\n",
    "all_samples = set(config_dataset[\"SAMPLE\"])\n",
    "top_n_genes_to_evaluate = int(config_dataset[\"top_n_genes_to_evaluate\"])\n",
    "top_n_genes_to_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3b155-e842-4774-86ae-305f4bb1f6a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genes = pd.read_csv(f\"{out_folder}/info_highly_variable_genes.csv\")\n",
    "selected_genes_bool = genes.isPredicted.values\n",
    "genes_predict = genes[selected_genes_bool]\n",
    "genes_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd455749-06eb-49f2-919c-d10ca189ede7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_genes_evaluate = genes_predict.variances_norm_rank <= top_n_genes_to_evaluate\n",
    "genes_evaluate = genes_predict[selected_genes_evaluate]\n",
    "genes_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abfeeb-ea24-4cd6-ad8c-03478998817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cross_validation_config.yaml\", \"r\") as stream:\n",
    "    cross_validation_config = yaml.safe_load(stream)\n",
    "cross_validation_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0cef8-776c-4cee-845b-b215d4396153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(validation_predictions, val_barcode, test_barcode, genes):\n",
    "    for param_pickle_val_path in validation_predictions:\n",
    "        val_pred = pd.read_pickle(param_pickle_val_path)\n",
    "        val_pred = val_pred.loc[val_barcode]\n",
    "        val_pred = val_pred[genes]\n",
    "\n",
    "        \n",
    "        param_pickle_test_path = param_pickle_val_path.replace(\"_validation\", \"_test\")\n",
    "        test_pred = pd.read_pickle(param_pickle_test_path)\n",
    "        test_pred = test_pred.loc[test_barcode]\n",
    "        test_pred = test_pred[genes]\n",
    "        \n",
    "        param_name = param_pickle_val_path.split(\"/\")[-1].split(\".pkl\")[0].replace('_validation', '')\n",
    "\n",
    "        yield val_pred, test_pred, param_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd5b85-4f65-445d-ad25-557555b5cb5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_correlations_per_fold(i, fold, out_folder):\n",
    "    \n",
    "    test_samples = \"_\".join(cross_validation_config[fold][\"test\"])\n",
    "    validation_samples = \"_\".join(cross_validation_config[fold][\"validation\"])\n",
    "    training_samples = \"_\".join(cross_validation_config[fold][\"training\"])\n",
    "    \n",
    "    validation_data = load_data(cross_validation_config[fold][\"validation\"], \n",
    "                            out_folder,\n",
    "                            load_image_features=False)\n",
    "\n",
    "    test_data = load_data(cross_validation_config[fold][\"test\"], \n",
    "                            out_folder,\n",
    "                            load_image_features=False)\n",
    "\n",
    "    val_true = pd.DataFrame(validation_data[\"y\"][:,selected_genes_bool], \n",
    "                         index=validation_data[\"barcode\"],\n",
    "                         columns=genes_predict.gene_name.values)\n",
    "    \n",
    "\n",
    "    test_true = pd.DataFrame(test_data[\"y\"][:,selected_genes_bool], \n",
    "                         index=test_data[\"barcode\"],\n",
    "                         columns=genes_predict.gene_name.values)\n",
    "\n",
    "    validation_predictions = glob.glob(f\"{out_folder}/evaluation/{test_samples}/{validation_samples}/{model}/prediction/*_validation.pkl\")\n",
    "\n",
    "    #prediction_scores_df = []\n",
    "    for val_pred, test_pred, param_name in load_predictions(validation_predictions, \n",
    "                                                            validation_data[\"barcode\"], \n",
    "                                                            test_data[\"barcode\"], \n",
    "                                                            genes_predict.gene_name.values):\n",
    "        \n",
    "        \n",
    "        pearson_score_val = val_true.corrwith(val_pred, method=\"pearson\").fillna(0) # nan = 0    \n",
    "        pearson_score_val.reset_index().to_csv(f\"{out_folder}/evaluation/{test_samples}/gene_scores/validation/{model}/{param_name}.csv\", index=False)\n",
    "        #prediction_scores_df.append(pearson_score_val)\n",
    "    \n",
    "        pearson_score_test = test_true.corrwith(test_pred, method=\"pearson\").fillna(0) # nan = 0\n",
    "        pearson_score_test.reset_index().to_csv(f\"{out_folder}/evaluation/{test_samples}/gene_scores/test/{model}/{param_name}.csv\", index=False)\n",
    "        \n",
    "\n",
    "        #prediction_scores_df.append(pearson_score_test)\n",
    "    #prediction_scores_df = pd.concat(prediction_scores_df)\n",
    "    #prediction_scores_df.to_csv(f\"{out_folder}/evaluation/{model}/gene_scores/{test_samples}_prediction_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b58009-1a8e-4364-b8b2-24a84deab05a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "delayed_compute_correlations_per_fold = delayed(compute_correlations_per_fold)\n",
    "n_threads = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12978e9-7b56-4623-9a0a-8412dcb87a64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Parallel(n_threads)(delayed_compute_correlations_per_fold(i, fold, out_folder) \n",
    "                                      for i, fold in \n",
    "                                          enumerate(tqdm(cross_validation_config))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd02a1f-29e0-4c44-8920-f2bf4cf8c5f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f\"{out_folder}/evaluation/*/gene_scores/*/{model}/*.csv\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c28b3-d4a1-4b6a-8725-21d0f0dba43f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for file in tqdm(files):\n",
    "    file_csv = file\n",
    "    file = file.split(\"/\")\n",
    "    performance_set = file[4] \n",
    "    test = file[2]\n",
    "    param = file[6].split(\".csv\")[0]\n",
    "\n",
    "    df = pd.read_csv(file_csv)\n",
    "    df.columns = [\"gene\", \"score\"]\n",
    "    df[\"performance_set\"] = performance_set\n",
    "    df[\"test_sample\"] = test\n",
    "    df[\"model\"] = param\n",
    "    scores.append(df)\n",
    "\n",
    "scores = pd.concat(scores)\n",
    "scores = scores.pivot_table(columns=\"performance_set\", values=\"score\", index=[\"gene\", \"test_sample\", \"model\"]).reset_index()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1358a46-75f9-4be1-bf37-093595fbb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_top_n = compute_pearson_top_n(scores, \"model\", genes_predict,)\n",
    "score_top_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aef919-3b2a-41e6-b473-dc9cce7dcc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = score_top_n.groupby([\"gene\", \"model\", \"top_n\"]).validation.agg(\"mean\").reset_index()\n",
    "g = (p9.ggplot(df_plot, p9.aes(\"validation\", color=\"model\")) \n",
    " + p9.geom_density()\n",
    " + p9.facet_wrap(\"~top_n\", ncol=1, scales=\"free_y\")\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(20, 12), legend_position='none')\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/{model}/pearson_score_val_distribution.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c921316-99e3-473c-95fc-3085bb166acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_val = score_top_n.groupby([\"gene\", \"model\", \"top_n\"]).validation.agg(\"mean\").reset_index()\n",
    "tab_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee0f44-09ea-438d-a939-1506e264f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_val = compute_area_under_pearson_top_n(tab_val, \"model\", \"validation\")\n",
    "auc_scores_val.model = pd.Categorical(auc_scores_val.model, auc_scores_val.sort_values(\"auc_mean\", ascending=True).model)\n",
    "auc_scores_val_dict = auc_scores_val.set_index(\"model\")[[\"auc_mean\", \"auc_std\"]].to_dict(\"index\")\n",
    "auc_scores_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e0723-5129-4262-823a-df06c4733d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dodge_width = 0.5\n",
    "g = (p9.ggplot(auc_scores_val, p9.aes(\"model\", \"auc_mean\", color=\"model\", group='model')) \n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"model\", ymin=\"auc_mean-auc_std\",\n",
    "                           ymax=\"auc_mean+auc_std\"), \n",
    "                    alpha=1, size=0.5, width=0.2, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"AU under pearson's highly variable genes curve\")\n",
    " + p9.xlab(\"Model\")\n",
    " + p9.ggtitle(\"Validation set\")\n",
    " + p9.coord_flip()\n",
    " + p9.theme(legend_position = \"none\", figure_size=(16,8))\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/pearson_score_top_top_n.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db579e80-3eba-41a0-acaa-d59ee6becd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_val = tab_val.groupby([\"model\", \"top_n\"]).validation.apply(lambda x: bootstrapping(x)).reset_index()\n",
    "df_plot = pd.DataFrame(tab_val[\"validation\"].to_list(), columns=['pearson_median', 'pearson_std'])\n",
    "df_plot[\"model\"] = tab_val.model\n",
    "df_plot[\"top_n\"] = tab_val.top_n\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab3f56-7f35-4476-b9f3-7b1421e24ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[\"model\"] = pd.Categorical(df_plot[\"model\"], auc_scores_val.sort_values(\"auc_mean\", ascending=False).model)\n",
    "df_plot[\"model_AUC\"] = df_plot.model.apply(lambda x: f\"{x}: {auc_scores_val_dict[x]['auc_mean']:.2f}±{auc_scores_val_dict[x]['auc_std']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa61b6d-20f7-4247-95bb-fe09e6b1cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_to_plot = df_plot[df_plot.top_n.astype(int) == top_n_genes_to_evaluate]\n",
    "top_model_to_plot = top_model_to_plot.groupby(\"model\").pearson_median.agg('median').sort_values(ascending=True)[-6:].index.values\n",
    "df_plot = df_plot.query('model in @top_model_to_plot')\n",
    "top_model_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47306f7f-7c9b-43b1-9df0-2657f8c2ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dodge_width = 0.5\n",
    "df_plot.top_n = pd.Categorical(df_plot.top_n.astype(str), \n",
    "                                    df_plot.top_n.drop_duplicates().sort_values().astype(str))\n",
    "g = (p9.ggplot(df_plot, p9.aes(\"top_n\", \"pearson_median\", color=\"model_AUC\", group='model_AUC')) \n",
    " + p9.geom_line(linetype=\"dashed\", alpha=0.8, position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"top_n\", ymin=\"pearson_median-pearson_std\",\n",
    "                           ymax=\"pearson_median+pearson_std\"), \n",
    "                    alpha=0.5, size=0.3, width=1, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"Pearson correlation\")\n",
    " + p9.xlab(\"Top highly variable genes\")\n",
    " + p9.ggtitle(\"Validation set\")\n",
    " + p9.theme(figure_size=(14, 10), legend_position='none')\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/{model}/pearson_score_per_top_n_validation.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe54a5-5652-4e38-9e8e-83951146a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_plot[df_plot.top_n.astype(int) == top_n_genes_to_evaluate]\n",
    "df_plot.model = pd.Categorical(df_plot.model, df_plot.groupby(\"model\").pearson_median.agg('median').sort_values(ascending=True).index)\n",
    "g = (p9.ggplot(df_plot, p9.aes(\"model\", \"pearson_median\", color=\"model\", group='model')) \n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"model\", ymin=\"pearson_median-pearson_std\",\n",
    "                           ymax=\"pearson_median+pearson_std\"), \n",
    "                    alpha=1, size=0.5, width=0.2, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"Pearson correlation\")\n",
    " + p9.xlab(\"model\")\n",
    " + p9.ggtitle(\"Validation set\")\n",
    " + p9.coord_flip()\n",
    " + p9.theme(legend_position = \"none\", figure_size=(18, 6))\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/{model}/pearson_score_top_n_validation.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59063149-3658-4ea5-ab77-bdb5e693c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_test = score_top_n.groupby([\"gene\", \"model\", \"top_n\"]).test.agg(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551290f-8e35-4e35-919e-d363b22346e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_test = compute_area_under_pearson_top_n(tab_test, \"model\", \"test\")\n",
    "auc_scores_test.model = pd.Categorical(auc_scores_test.model, auc_scores_test.sort_values(\"auc_mean\", ascending=True).model)\n",
    "auc_scores_test_dict = auc_scores_test.set_index(\"model\")[[\"auc_mean\", \"auc_std\"]].to_dict(\"index\")\n",
    "auc_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbc83b-dd6f-4c13-87df-fbeb3a99fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dodge_width = 0.5\n",
    "g = (p9.ggplot(auc_scores_test, p9.aes(\"model\", \"auc_mean\", color=\"model\", group='model')) \n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"model\", ymin=\"auc_mean-auc_std\",\n",
    "                           ymax=\"auc_mean+auc_std\"), \n",
    "                    alpha=1, size=0.5, width=0.2, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"AU under pearson's highly variable genes curve\")\n",
    " + p9.xlab(\"Model\")\n",
    " + p9.ggtitle(\"Test set\")\n",
    " + p9.coord_flip()\n",
    " + p9.theme(legend_position = \"none\", figure_size=(16,8))\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/pearson_score_top_top_n.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc8e00-349c-4e09-8989-6437882f3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_test = tab_test.groupby([\"model\", \"top_n\"]).test.apply(lambda x: bootstrapping(x)).reset_index()\n",
    "df_plot = pd.DataFrame(tab_test[\"test\"].to_list(), columns=['pearson_median', 'pearson_std'])\n",
    "df_plot[\"model\"] = tab_test.model\n",
    "df_plot[\"top_n\"] = tab_test.top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92e780-f85e-4767-970d-fc25bfb6fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[\"model\"] = pd.Categorical(df_plot[\"model\"], auc_scores_test.sort_values(\"auc_mean\", ascending=True).model)\n",
    "df_plot[\"model_AUC\"] = df_plot.model.apply(lambda x: f\"{x}: {auc_scores_test_dict[x]['auc_mean']:.2f}±{auc_scores_test_dict[x]['auc_std']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d856d9-6f1f-4f91-bd14-d677e6985768",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_to_plot = df_plot[df_plot.top_n.astype(int) == top_n_genes_to_evaluate]\n",
    "top_model_to_plot = top_model_to_plot.groupby(\"model\").pearson_median.agg('median').sort_values(ascending=True)[-6:].index.values\n",
    "df_plot = df_plot.query('model in @top_model_to_plot')\n",
    "top_model_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60583a4-40ce-4896-bfab-ce6263c34d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dodge_width = 0.5\n",
    "df_plot.top_n = pd.Categorical(df_plot.top_n.astype(str), \n",
    "                                    df_plot.top_n.drop_duplicates().sort_values().astype(str))\n",
    "g = (p9.ggplot(df_plot, p9.aes(\"top_n\", \"pearson_median\", color=\"model_AUC\", group='model_AUC')) \n",
    " + p9.geom_line(linetype=\"dashed\", alpha=0.8, position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"top_n\", ymin=\"pearson_median-pearson_std\",\n",
    "                           ymax=\"pearson_median+pearson_std\"), \n",
    "                    alpha=0.5, size=0.3, width=1, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"Pearson correlation\")\n",
    " + p9.xlab(\"Top highly variable genes\")\n",
    " + p9.ggtitle(\"Test set\")\n",
    " + p9.theme(figure_size=(14, 10), legend_position='none')\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/{model}/pearson_score_per_top_n_test.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616ec40-08eb-4d98-949e-8abff94536a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_plot[df_plot.top_n.astype(int) == top_n_genes_to_evaluate]\n",
    "df_plot.model = pd.Categorical(df_plot.model, \n",
    "                               df_plot.groupby(\"model\").pearson_median.agg('median').sort_values(ascending=True).index)\n",
    "g = (p9.ggplot(df_plot, p9.aes(\"model\", \"pearson_median\", color=\"model\", group='model')) \n",
    " + p9.geom_point(position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.geom_errorbar(p9.aes(x=\"model\", ymin=\"pearson_median-pearson_std\",\n",
    "                           ymax=\"pearson_median+pearson_std\"), \n",
    "                    alpha=1, size=0.5, width=0.2, position=p9.position_dodge(width=position_dodge_width))\n",
    "# + scale_color_prism(palette = \"colors\")\n",
    " + p9.ylab(\"Pearson correlation\")\n",
    " + p9.xlab(\"Model\")\n",
    " + p9.ggtitle(\"Test set\")\n",
    " + p9.coord_flip()\n",
    " + p9.theme(legend_position = \"none\", figure_size=(14, 6))\n",
    ")\n",
    "#g.save(f\"{out_folder}/evaluation/{model}/pearson_score_top_n_test.png\", dpi=300)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89cc28-cd4f-4991-9cb4-fc8c38f62c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_scores_val_evaluate_decentile = score_top_n[score_top_n.top_n.astype(int) == top_n_genes_to_evaluate]\n",
    "top_n_scores_val_evaluate_decentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd445428-2faa-41f1-b8a0-b07ee49d206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_per_sample = top_n_scores_val_evaluate_decentile.groupby([\"test_sample\", \"model\", \"top_n\"]).validation.agg(\"mean\").reset_index()\n",
    "top_model_per_sample = top_model_per_sample.sort_values('validation').drop_duplicates(['test_sample'], keep='last')\n",
    "top_model_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26012f-80d1-414a-a1d0-a673b7da9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_val = score_top_n.groupby([\"gene\", \"model\", \"top_n\", \"test_sample\"]).validation.agg(\"mean\").reset_index()\n",
    "top_model_per_sample = tab_val.groupby(\"test_sample\").apply(lambda x: compute_area_under_pearson_top_n(x, \"model\", \"validation\").sort_values(\"auc_mean\", ascending=False)[:1]).reset_index()\n",
    "top_model_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b67b71-0cb9-4bcb-95a9-1f7688e3d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_per_sample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145f4e5-f82e-42cb-87bf-f52a08982b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_per_sample.to_csv(f\"{out_folder}/evaluation/{model}/top_model_per_test_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4e447-035f-4485-9af1-9e10f4724e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = top_model_per_sample.model.value_counts().sort_values(ascending=False).reset_index()\n",
    "best_model.columns = [\"model_name\", \"num\"]\n",
    "best_model.to_csv(f\"{out_folder}/evaluation/{model}/top_model_overall.csv\", index=False)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61aa6b-d52b-4602-bcd2-41e737c950ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_overall = best_model.model_name[0]\n",
    "top_model_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a027aea-230f-41a4-ad78-73cad89e1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_file = glob.glob(f\"{out_folder}/evaluation/*/*/{model}/parameters/*.yaml\")\n",
    "top_model_file = [f for f in top_model_file if top_model_overall in f][0] # we cant filter on glob level.. an issue with re patterns\n",
    "shutil.move(top_model_file, f\"{out_folder}/evaluation/{model}/top_param_overall.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa19923-e7a1-43c8-9e58-2c8c87221458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nonchev",
   "language": "python",
   "name": "nonchev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
